{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1050'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bytes allocated\n"
     ]
    }
   ],
   "source": [
    "print(f\"{torch.cuda.memory_allocated()} bytes allocated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_reserved()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.FloatTensor([1.0,2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.device # we want thos to be in gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.FloatTensor([1.0,2.0]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 bytes of memory is not being used to store the tensor b\n"
     ]
    }
   ],
   "source": [
    "print(f\"{torch.cuda.memory_allocated()} bytes of memory is not being used to store the tensor b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.RandomRotation(degrees=10),\n",
    "                                       transforms.RandomHorizontalFlip(p = 0.5),\n",
    "                                       transforms.Resize((224,224)),\n",
    "                                      transforms.CenterCrop((224,224)),\n",
    "                                      transforms.ToTensor(), \n",
    "                                      transforms.Normalize(mean = [0.485,0.456,0.406], std = [0.229,0.224,0.225])])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                      transforms.CenterCrop((224,224)),\n",
    "                                      transforms.ToTensor(), \n",
    "                                      transforms.Normalize(mean = [0.485,0.456,0.406], std = [0.229,0.224,0.225])])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 batch 600 and loss 1.0463640689849854 and accuracy is 88.48333333333333%\n",
      "Epoch 0 batch 1200 and loss 0.00056585727725178 and accuracy is 89.7%\n",
      "Epoch 0 batch 1800 and loss 0.006783259566873312 and accuracy is 90.68888888888888%\n"
     ]
    }
   ],
   "source": [
    "root = r\"D:\\PyTorch for Deep Learning with Python Bootcamp\\1. Course Overview, Installs, and Setup\\PYTORCH_NOTEBOOKS\\Images\\CATS_DOGS\"\n",
    "\n",
    "torch.manual_seed(1429)\n",
    "train_data = datasets.ImageFolder(os.path.join(root, 'train'), transform = train_transform)\n",
    "test_data = datasets.ImageFolder(os.path.join(root, 'test'), transform = test_transform)\n",
    "train_loader = DataLoader(train_data,batch_size = 10, shuffle = True,pin_memory = True )\n",
    "test_loader = DataLoader(test_data,batch_size = 10, shuffle = False,pin_memory = True)\n",
    "class_names = train_data.classes\n",
    "\n",
    "# for img, lbl in train_loader:\n",
    "#     break\n",
    "\n",
    "# img.shape\n",
    "\n",
    "# inv_normalize = transforms.Compose([transforms.Normalize(mean= [-0.485/0.229,-0.456/0.224,-0.406/0.225], std = [1/0.229,1/0.224,1/0.225])])\n",
    "# im = inv_normalize(img[5])\n",
    "# plt.imshow(np.transpose((im.numpy()), (1,2,0)))\n",
    "\n",
    "# Model\n",
    "\n",
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1) #out_channel = no of filters, kernel_size = filter dim \n",
    "#         self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3, stride=1)\n",
    "#         self.fc1 = nn.Linear(54*54*16,120) # out_channels from conv1, in/out_channel from conv2\n",
    "#         self.fc2 = nn.Linear(120,84)\n",
    "#         self.fc3 = nn.Linear(84,2) # output as 10 classes\n",
    "        \n",
    "#     def forward(self,X):\n",
    "#         X = F.relu(self.conv1(X))\n",
    "#         X = F.max_pool2d(X,2,2)\n",
    "#         X = F.relu(self.conv2(X))\n",
    "#         X = F.max_pool2d(X,2,2)\n",
    "#         X = X.view(-1,54*54*16)\n",
    "#         X = F.relu(self.fc1(X))\n",
    "#         X = F.relu(self.fc2(X))\n",
    "#         X = self.fc3(X)\n",
    "#         return F.log_softmax(X, dim = 1)\n",
    "alex_net = models.alexnet(pretrained=True).cuda()\n",
    "for param in alex_net.parameters():\n",
    "    param.requires_grad = False\n",
    "torch.manual_seed(1429)\n",
    "alex_net.classifier = nn.Sequential(nn.Linear(in_features=9216, out_features=1024),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Dropout(p = 0.5),\n",
    "                                   nn.Linear(in_features=1024, out_features=2),\n",
    "                                   nn.LogSoftmax(dim = 1)) # nn.Sequential allows us to quickly add layers\n",
    "alex_net = models.alexnet(pretrained=True).cuda()\n",
    "\n",
    "\n",
    "torch.manual_seed(1429)\n",
    "# model = alex_net().cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(alex_net.classifier.parameters(), lr = 1e-3)\n",
    "\n",
    "\n",
    "# for param in model.parameters():\n",
    "\n",
    "#     print(param.numel())\n",
    "\n",
    "\n",
    "epochs = 1\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    test_corr = 0\n",
    "    \n",
    "    \n",
    "    for batch, (X_train, y_train) in enumerate(train_loader):\n",
    "        X_train = torch.FloatTensor(X_train).cuda()\n",
    "        y_train = torch.LongTensor(y_train).cuda()\n",
    "        batch = batch+1\n",
    "        y_pred = alex_net(X_train)\n",
    "        losses = criterion(y_pred,y_train)\n",
    "        pred = torch.max(y_pred.data,1)[1]\n",
    "        \n",
    "        batch_corr = (pred == y_train).sum() # True 1 / False 0\n",
    "        \n",
    "        trn_corr = trn_corr+batch_corr\n",
    "         \n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch%600 == 0:\n",
    "            print(f'Epoch {i} batch {batch} and loss {losses} and accuracy is {trn_corr.item()*100/(10*batch)}%')\n",
    "    train_loss.append(losses)\n",
    "    train_correct.append(trn_corr)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch, (X_test, y_test) in enumerate(test_loader):\n",
    "            X_test = torch.FloatTensor(X_test).cuda()\n",
    "            y_test = torch.LongTensor(y_test).cuda()\n",
    "            y_val = model(X_test)\n",
    "            \n",
    "            predicted = torch.max(y_val.data,1)[1]\n",
    "            \n",
    "            test_corr = test_corr + (predicted == y_test).sum()\n",
    "        losses = criterion(y_val, y_test)\n",
    "        test_loss.append(losses)\n",
    "        test_correct.append(test_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
